{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b08247",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision opencv-python facenet-pytorch\n",
    "!pip install numpy\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "!cd yolov5\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8d0d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-411-gf4d8a84c Python-3.12.4 torch-2.2.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading known faces...\n",
      "Loaded 1 persons\n",
      "  - sushmit: 10 without mask, 0 with mask\n",
      "Press 'q' to quit\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLOv5 model for face mask detection\n",
    "yolo_model = torch.hub.load('yolov5', 'custom', path='last.pt', source='local')\n",
    "\n",
    "# Define class names based on your YOLOv5 model training\n",
    "class_names = ['without_mask', 'with_mask', 'mask_weared_incorrect']\n",
    "\n",
    "# Initialize MTCNN and FaceNet for face recognition\n",
    "mtcnn = MTCNN(image_size=160, margin=20, keep_all=True, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "facenet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "if torch.cuda.is_available():\n",
    "    facenet = facenet.cuda()\n",
    "\n",
    "# Modified function to load known faces with and without masks\n",
    "def load_known_faces(known_dir='known_faces'):\n",
    "    embeddings = {}\n",
    "    \n",
    "    # If the directory is flat (contains only image files)\n",
    "    if all(os.path.isfile(os.path.join(known_dir, f)) for f in os.listdir(known_dir) if not f.startswith('.')):\n",
    "        # Create a default person name based on directory name\n",
    "        person_name = os.path.basename(known_dir)\n",
    "        embeddings[person_name] = {\n",
    "            'with_mask': [],\n",
    "            'without_mask': []\n",
    "        }\n",
    "        \n",
    "        for img_file in os.listdir(known_dir):\n",
    "            if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                continue\n",
    "                \n",
    "            path = os.path.join(known_dir, img_file)\n",
    "            is_masked = 'mask' in img_file.lower()\n",
    "            \n",
    "            # Try both regular and flipped images for better recognition\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            img_flipped = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "            # Process original image\n",
    "            faces = mtcnn(img)\n",
    "            if faces is not None:\n",
    "                if isinstance(faces, list):\n",
    "                    face = faces[0] if faces else None\n",
    "                else:\n",
    "                    face = faces\n",
    "                    \n",
    "                if face is not None:\n",
    "                    if torch.cuda.is_available():\n",
    "                        face = face.cuda()\n",
    "                    emb = facenet(face.unsqueeze(0) if len(face.shape) == 3 else face).detach()\n",
    "                    \n",
    "                    if is_masked:\n",
    "                        embeddings[person_name]['with_mask'].append(emb)\n",
    "                    else:\n",
    "                        embeddings[person_name]['without_mask'].append(emb)\n",
    "            \n",
    "            # Process flipped image\n",
    "            faces_flipped = mtcnn(img_flipped)\n",
    "            if faces_flipped is not None:\n",
    "                if isinstance(faces_flipped, list):\n",
    "                    face_flipped = faces_flipped[0] if faces_flipped else None\n",
    "                else:\n",
    "                    face_flipped = faces_flipped\n",
    "                    \n",
    "                if face_flipped is not None:\n",
    "                    if torch.cuda.is_available():\n",
    "                        face_flipped = face_flipped.cuda()\n",
    "                    emb_flipped = facenet(face_flipped.unsqueeze(0) if len(face_flipped.shape) == 3 else face_flipped).detach()\n",
    "                    \n",
    "                    if is_masked:\n",
    "                        embeddings[person_name]['with_mask'].append(emb_flipped)\n",
    "                    else:\n",
    "                        embeddings[person_name]['without_mask'].append(emb_flipped)\n",
    "    else:\n",
    "        # Process hierarchical directory structure\n",
    "        for person_name in os.listdir(known_dir):\n",
    "            person_dir = os.path.join(known_dir, person_name)\n",
    "            \n",
    "            if os.path.isdir(person_dir):\n",
    "                embeddings[person_name] = {\n",
    "                    'with_mask': [],\n",
    "                    'without_mask': []\n",
    "                }\n",
    "                \n",
    "                for img_file in os.listdir(person_dir):\n",
    "                    if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        continue\n",
    "                        \n",
    "                    path = os.path.join(person_dir, img_file)\n",
    "                    is_masked = 'mask' in img_file.lower()\n",
    "                    \n",
    "                    # Try both regular and flipped images\n",
    "                    img = Image.open(path).convert('RGB')\n",
    "                    img_flipped = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                    \n",
    "                    # Process original image\n",
    "                    faces = mtcnn(img)\n",
    "                    if faces is not None:\n",
    "                        if isinstance(faces, list):\n",
    "                            face = faces[0] if faces else None\n",
    "                        else:\n",
    "                            face = faces\n",
    "                            \n",
    "                        if face is not None:\n",
    "                            if torch.cuda.is_available():\n",
    "                                face = face.cuda()\n",
    "                            emb = facenet(face.unsqueeze(0) if len(face.shape) == 3 else face).detach()\n",
    "                            \n",
    "                            if is_masked:\n",
    "                                embeddings[person_name]['with_mask'].append(emb)\n",
    "                            else:\n",
    "                                embeddings[person_name]['without_mask'].append(emb)\n",
    "                    \n",
    "                    # Process flipped image\n",
    "                    faces_flipped = mtcnn(img_flipped)\n",
    "                    if faces_flipped is not None:\n",
    "                        if isinstance(faces_flipped, list):\n",
    "                            face_flipped = faces_flipped[0] if faces_flipped else None\n",
    "                        else:\n",
    "                            face_flipped = faces_flipped\n",
    "                            \n",
    "                        if face_flipped is not None:\n",
    "                            if torch.cuda.is_available():\n",
    "                                face_flipped = face_flipped.cuda()\n",
    "                            emb_flipped = facenet(face_flipped.unsqueeze(0) if len(face_flipped.shape) == 3 else face_flipped).detach()\n",
    "                            \n",
    "                            if is_masked:\n",
    "                                embeddings[person_name]['with_mask'].append(emb_flipped)\n",
    "                            else:\n",
    "                                embeddings[person_name]['without_mask'].append(emb_flipped)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Load known faces\n",
    "print(\"Loading known faces...\")\n",
    "known_embeddings = load_known_faces()\n",
    "print(f\"Loaded {len(known_embeddings)} persons\")\n",
    "for person, data in known_embeddings.items():\n",
    "    print(f\"  - {person}: {len(data['without_mask'])} without mask, {len(data['with_mask'])} with mask\")\n",
    "\n",
    "# Modified function to recognize faces with or without masks\n",
    "def recognize_face(face_embedding, mask_status, threshold=0.9):\n",
    "    min_dist = float('inf')\n",
    "    identity = \"Unknown\"\n",
    "    \n",
    "    # Compare with embeddings from all categories to improve recognition\n",
    "    for person_name, emb_dict in known_embeddings.items():\n",
    "        # Try both mask categories for better recognition\n",
    "        for compare_type in ['with_mask', 'without_mask']:\n",
    "            if not emb_dict[compare_type]:\n",
    "                continue\n",
    "            \n",
    "            # Compare with all embeddings of this type\n",
    "            for known_emb in emb_dict[compare_type]:\n",
    "                dist = (face_embedding - known_emb).norm().item()\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    identity = person_name\n",
    "    \n",
    "    # Apply threshold\n",
    "    return identity if min_dist < threshold else \"Unknown\", min_dist\n",
    "\n",
    "# Start webcam for real-time detection\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"Press 'q' to quit\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Flip the frame horizontally to correct the mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Create a copy for display\n",
    "    display_frame = frame.copy()\n",
    "    \n",
    "    # Perform detection with YOLOv5\n",
    "    results = yolo_model(frame)\n",
    "    detections = results.xyxy[0]  # x1, y1, x2, y2, conf, class\n",
    "    \n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2, conf, cls = det.cpu().numpy()\n",
    "        x1, y1, x2, y2, cls = int(x1), int(y1), int(x2), int(y2), int(cls)\n",
    "        \n",
    "        # Skip detections with low confidence\n",
    "        if conf < 0.5:\n",
    "            continue\n",
    "            \n",
    "        face_crop = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        if face_crop.size == 0:\n",
    "            continue\n",
    "        \n",
    "        # Convert face to RGB and process with MTCNN\n",
    "        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "        face_pil = Image.fromarray(face_rgb)\n",
    "        \n",
    "        # Also try with a flipped version of the face\n",
    "        face_pil_flipped = face_pil.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        # Process both regular and flipped face\n",
    "        face_tensors = mtcnn(face_pil)\n",
    "        face_tensors_flipped = mtcnn(face_pil_flipped)\n",
    "        \n",
    "        identity = \"Unknown\"\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        # Get mask status from the model\n",
    "        original_mask_status = class_names[cls]\n",
    "        \n",
    "        # Custom mask detection rule: \n",
    "        # If without_mask confidence is > 90, person is wearing mask\n",
    "        # If without_mask confidence is < 90, person is not wearing mask\n",
    "        without_mask_conf = conf * 100 if cls == 0 else 0\n",
    "        \n",
    "        # Apply the custom rule\n",
    "        if original_mask_status == 'without_mask':\n",
    "            if without_mask_conf > 91.8:\n",
    "                custom_mask_status = \"with_mask\"\n",
    "            else:\n",
    "                custom_mask_status = \"without_mask\"\n",
    "        else:\n",
    "            custom_mask_status = original_mask_status\n",
    "        \n",
    "        # Try recognition with regular face\n",
    "        if face_tensors is not None:\n",
    "            if isinstance(face_tensors, list):\n",
    "                face_tensor = face_tensors[0] if face_tensors else None\n",
    "            else:\n",
    "                face_tensor = face_tensors\n",
    "                \n",
    "            if face_tensor is not None:\n",
    "                if torch.cuda.is_available():\n",
    "                    face_tensor = face_tensor.cuda()\n",
    "                emb = facenet(face_tensor.unsqueeze(0) if len(face_tensor.shape) == 3 else face_tensor)\n",
    "                name, distance = recognize_face(emb, custom_mask_status)\n",
    "                \n",
    "                if distance < min_distance:\n",
    "                    identity = name\n",
    "                    min_distance = distance\n",
    "        \n",
    "        # Try recognition with flipped face\n",
    "        if face_tensors_flipped is not None:\n",
    "            if isinstance(face_tensors_flipped, list):\n",
    "                face_tensor_flipped = face_tensors_flipped[0] if face_tensors_flipped else None\n",
    "            else:\n",
    "                face_tensor_flipped = face_tensors_flipped\n",
    "                \n",
    "            if face_tensor_flipped is not None:\n",
    "                if torch.cuda.is_available():\n",
    "                    face_tensor_flipped = face_tensor_flipped.cuda()\n",
    "                emb_flipped = facenet(face_tensor_flipped.unsqueeze(0) if len(face_tensor_flipped.shape) == 3 else face_tensor_flipped)\n",
    "                name_flipped, distance_flipped = recognize_face(emb_flipped, custom_mask_status)\n",
    "                \n",
    "                if distance_flipped < min_distance:\n",
    "                    identity = name_flipped\n",
    "                    min_distance = distance_flipped\n",
    "        \n",
    "        # Determine color based on custom mask status\n",
    "        if custom_mask_status == \"with_mask\":\n",
    "            color = (0, 255, 0)  # Green\n",
    "        elif custom_mask_status == \"mask_weared_incorrect\":\n",
    "            color = (0, 165, 255)  # Orange\n",
    "        else:\n",
    "            color = (0, 0, 255)  # Red\n",
    "        \n",
    "        # Draw bounding box and label\n",
    "        label = f\"{identity} - {custom_mask_status} ({min_distance:.2f})\"\n",
    "        cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(display_frame, label, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "        # Display the without_mask confidence for debugging\n",
    "        cv2.putText(display_frame, f\"Without mask conf: {without_mask_conf:.1f}\", \n",
    "                   (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        # Show both original and custom status\n",
    "        if original_mask_status != custom_mask_status:\n",
    "            cv2.putText(display_frame, f\"Model: {original_mask_status}, Custom: {custom_mask_status}\", \n",
    "                       (x1, y2 + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    \n",
    "    # Display detection information\n",
    "    if len(detections) > 0:\n",
    "        text = f\"Detections: {len(detections)}\"\n",
    "        cv2.putText(display_frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"Face & Mask Recognition\", display_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
